{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport io\nimport re\nimport sys\n!{sys.executable} -m pip install gensim\n!{sys.executable} -m pip install nltk\nimport gensim\nimport nltk\nnltk.download('punkt') #nltk Dependency\nfrom gensim.models.doc2vec import Doc2Vec,TaggedDocument\nfrom nltk.tokenize import word_tokenize\nfrom datetime import datetime,date,timedelta\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"newsDataframe = pd.read_csv('../input/newssampledata.csv')\nmarketDataframe = pd.read_csv('../input/marketsampledata.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a7013e179fc445a8619831d21ea9436a1df0170"},"cell_type":"code","source":"newsDataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7cae2e098ab03de138fef8817a1755686bac6583"},"cell_type":"code","source":"marketDataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9bd18ce31a19c3d544ae02623368d3e2a62a1221"},"cell_type":"code","source":"%%time\ninputMktData = pd.DataFrame()\ninputMktData['date'] = marketDataframe['time']\ninputMktData['date'] =  pd.to_datetime(inputMktData['date'])\ninputMktData['date']=inputMktData['date'].dt.strftime('%d-%m-%Y')\ninputMktData['date'] =  pd.to_datetime(inputMktData['date'])\ninputMktData['assetName'] = marketDataframe['assetName']\ninputMktData['volume'] = marketDataframe['volume']\ninputMktData['close'] = marketDataframe['close']\ninputMktData['open'] = marketDataframe['open']\ninputNewsData = pd.DataFrame()\ninputNewsData['date'] = newsDataframe['time']\ninputNewsData['date'] =  pd.to_datetime(inputNewsData['date'])\ninputNewsData['date']=inputNewsData['date'].dt.strftime('%d-%m-%Y')\ninputNewsData['date'] =  pd.to_datetime(inputNewsData['date'])\ninputNewsData['headline'] = newsDataframe['headline']\ninputNewsData['urgency'] = newsDataframe['urgency']\ninputNewsData['subjects'] = newsDataframe['subjects']\ninputNewsData['audiences'] = newsDataframe['audiences']\ninputNewsData['audiences'] = newsDataframe['audiences']\ninputNewsData['assetName'] = newsDataframe['assetName']\ninputNewsData['relevance'] = newsDataframe['relevance']\ninputNewsData['sentimentNegative'] = newsDataframe['sentimentNegative']\ninputNewsData['sentimentNeutral'] = newsDataframe['sentimentNeutral']\ninputNewsData['sentimentPositive'] = newsDataframe['sentimentPositive']\ndel newsDataframe,marketDataframe\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42ce90b1e39ded0527f6dca8ac1f1c696632c5d8"},"cell_type":"code","source":"inputNewsData = inputNewsData.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99e5092f49788f34973f31fe234a52562bfe9e53"},"cell_type":"code","source":"inputNewsData.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac52eae90cd39bdff3b04c3044148abb45c1a5c9"},"cell_type":"code","source":"inputMktData.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"210d25aefc783e772ac07f160a884a64191c5c4b"},"cell_type":"code","source":"newsHeadlineData = inputNewsData['headline'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c72d8361acd243762eb1489b89af9093bbca3059"},"cell_type":"code","source":"%%time\ntagged_data = [TaggedDocument(words=word_tokenize(str(_d).lower()), tags=[str(i)]) for i, _d in enumerate(newsHeadlineData)]\nmax_epochs = 5\nvec_size = 25\nalpha = 0.025\nmodel = Doc2Vec(size=vec_size,\n                alpha=alpha, \n                min_alpha=0.00025,\n                min_count=1,\n                dm =1)\nmodel.build_vocab(tagged_data)\nfor epoch in range(max_epochs):\n    print('iteration {0}'.format(epoch))\n    model.train(tagged_data,\n                total_examples=model.corpus_count,\n                epochs=model.iter)\n    model.alpha -= 0.0002\n    model.min_alpha = model.alpha\n\nmodel.save(\"d2v.model\")\ndel tagged_data\nprint(\"Model Saved\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"877046347e9df98f3ed707755cab135ce5ce9cf0"},"cell_type":"code","source":"def longestVector(arr):\n  k=-1\n  maximum = -2\n  for i in range(len(arr)):\n    k = len(arr.item(i))\n    if k>maximum:\n      maximum = k\n      index = i\n  regex = r\"[']([a-zA-z]*)[']\"\n  line = arr.item(index)\n  matchObj = re.findall(regex, line, re.M|re.I)\n  length = len(matchObj)\n  return length\n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea79764f631959eaee421f981756d3219142ca8c"},"cell_type":"code","source":"def setOfAllCategories(arr):\n  allCats = set()\n  regex = r\"[']([a-zA-z]*)[']\"\n  for i in range(len(arr)):\n    line = arr.item(i)\n    matchObj = re.findall(regex, line, re.M|re.I)\n    for j in matchObj:\n      allCats.add(j)\n  return allCats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5867a5b5fe35b15a88400c19ece93a1b87933cbf"},"cell_type":"code","source":"def createDictVector(numCat,nors,vs,arr):\n  vectorFrame = pd.DataFrame(np.zeros((nors,vs)))\n  DictionaryOfCategory = dict(numCat)\n  DictCat = {v: k for k, v in DictionaryOfCategory.items()}\n  regex = r\"[']([a-zA-z]*)[']\"\n  for i in range(len(arr)):\n    line = arr.item(i)\n    matchObj = re.findall(regex, line, re.M|re.I)\n    k=0\n    for j in matchObj:\n      vectorFrame.at[i,k] = DictCat[j] \n      k = k+1\n  df = vectorFrame\n  df['features'] = df[df.columns.values].values.tolist()\n  vectorNpArray = df['features'].values\n  return vectorNpArray","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8758bb13c8786b5a692abaa65731bc342d4ea861"},"cell_type":"code","source":"def vectorization(obj):\n  print('Calculating the vector size')\n  vectorSize = longestVector(obj)\n  print('Creating a list of all unique category values')\n  categories = setOfAllCategories(obj)\n  categories = list(categories)\n  numberOfRows = len(obj)\n  print('Creating Numbered List of Categories')\n  numberedListOfCategories = enumerate(categories)\n  print('Making an array of feature')\n  featureVector = createDictVector(numberedListOfCategories,numberOfRows,vectorSize,obj)\n  print('Finished')\n  return featureVector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f06b806a237655c57b862971e7a108ee4372ea7f"},"cell_type":"code","source":"subjectArray = inputNewsData['subjects'].values\nfeatureVectorSubject = vectorization(subjectArray)\ndel subjectArray\nprint(featureVectorSubject)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"388b13fe054b335c49221136c26b8f3d2a39b98b"},"cell_type":"code","source":"audiencesArray = inputNewsData['audiences'].values\nfeatureVectorAudience = vectorization(audiencesArray)\ndel audiencesArray\nprint(featureVectorAudience)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bdc93618229cbf50e3df7a41fb28908e3e43a7b2"},"cell_type":"code","source":"def string2VecParser(obj):\n  tempVector2 = []\n  for i in range(len(obj)):\n      stringConv = re.findall( r'([\\d]*[.][\\d]*)[,]', str(obj[i]))\n      temp = []\n      for j in stringConv:\n        k = float(j)\n        temp.append(k)\n      tempVector = np.array(temp)\n      tempVector2.append(tempVector)\n  finalVector = np.array(tempVector2)\n  return finalVector\n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8470596e24b150a4944f9d21ec37f0dd6a7e660f"},"cell_type":"code","source":"def queryEngine(marketIndex, newsDate):\n  td = timedelta(days=1)\n  upper = -45\n  lower = 20\n  p = inputMktData.loc[(inputMktData['date'] <= newsDate - upper*td) & (inputMktData['assetName'] == marketIndex) & (inputMktData['date'] >= newsDate - lower*td)]\n  if p.empty:\n    return pd.Series((None,None,None,None,None,None))\n  labelFrameTemp = p[p['date'] >= newsDate]\n  labelFrameTemp = labelFrameTemp.reset_index()\n  if len(labelFrameTemp.index) < 5:\n    return pd.Series((None,None,None,None,None,None))\n  labelFrameTemp2 = pd.DataFrame()\n  labelFrameTemp2['volume']=labelFrameTemp['volume']\n  labelFrameTemp2['open']=labelFrameTemp['open']\n  labelFrameTemp2['close']=labelFrameTemp['close']\n  labelFrame = labelFrameTemp2.T\n  labelFrame['labelTemp'] = labelFrame[labelFrame.columns.values].values.tolist()\n  featureFrameTemp = p[p['date'] < newsDate]\n  featureFrameTemp = featureFrameTemp.reset_index()\n  featureFrameTemp2 = pd.DataFrame()\n  featureFrameTemp2['volume']=featureFrameTemp['volume']\n  featureFrameTemp2['open']=featureFrameTemp['open']\n  featureFrameTemp2['close']=featureFrameTemp['close']\n  featureFrame = featureFrameTemp2.T\n  featureFrame['featureTemp'] = featureFrame[featureFrame.columns.values].values.tolist()\n  label = labelFrame['labelTemp'].values\n  feature = featureFrame['featureTemp'].values\n  return pd.Series((label[0][:5],label[1][:5],label[2][:5],feature[0],feature[1],feature[2])) #label[volume open close] and feature[volume open close]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfec2b92fad7ca233e873288ef3ae6460262e720"},"cell_type":"code","source":"def assembler(obj):\n  assembledVector = pd.DataFrame()\n  assembledVector['Vector'] = obj[obj.columns.values].values.tolist()\n  return assembledVector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9182d5bcf606d606c78b73458b39265d36552e51"},"cell_type":"code","source":"def docvec(obj):\n  obj = str(obj).lower()\n  data = word_tokenize(obj)\n  return model.infer_vector(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa625fcce976efbdcb647f0470844a51fe4bc849"},"cell_type":"code","source":"def queryForPandas(row):\n  return queryEngine(str(row['assetName']), row['date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c820618cc1bdb49cd45843bc4167b19df3b65d9f"},"cell_type":"code","source":"%%time\n#news parsing\ninputNewsData['subjectFeatures'] = featureVectorSubject.tolist() #subject to vector\nprint('Subject Vectorized...')\ndel featureVectorSubject\ninputNewsData['audienceFeatures'] = featureVectorAudience.tolist() #audience to Vector\ndel featureVectorAudience\nprint('Audiences Vectorized...')\nprint('Headlines Vectorization Started')\ninputNewsData['headlineVector'] = inputNewsData['headline'].apply(docvec) #headline to Vector\ndel model\nprint('Headlines Vectorized...')\nprint('Creating Cleaner DataFrame')\nNewsDataframeFinal = pd.DataFrame()\nNewsDataframeFinal['date'] = inputNewsData['date'] \nNewsDataframeFinal['urgency'] = inputNewsData['urgency']\nNewsDataframeFinal['relevance'] = inputNewsData['relevance']\nNewsDataframeFinal['assetName'] = inputNewsData['assetName']\nNewsDataframeFinal['sentimentNegative'] = inputNewsData['sentimentNegative']\nNewsDataframeFinal['sentimentNeutral'] = inputNewsData['sentimentNeutral']\nNewsDataframeFinal['sentimentPositive'] = inputNewsData['sentimentPositive']\nNewsDataframeFinal['subjectFeatures'] = inputNewsData['subjectFeatures']\nNewsDataframeFinal['audienceFeatures'] = inputNewsData['audienceFeatures']\nNewsDataframeFinal['headlineVector'] = inputNewsData['headlineVector']\ndel inputNewsData\nprint('DataFrame Creation Complete...')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed764b3a292289258510046e01cec6049a0d4270"},"cell_type":"code","source":"%%time\nprint('Query Engine Started...')\nNewsDataframeFinal['labelVolume'] = np.nan\nNewsDataframeFinal['labelOpen'] = np.nan\nNewsDataframeFinal['labelClose'] = np.nan\nNewsDataframeFinal['featureVolume'] = np.nan\nNewsDataframeFinal['featureOpen'] = np.nan\nNewsDataframeFinal['featureClose'] = np.nan\nNewsDataframeFinal[['labelVolume','labelOpen','labelClose','featureVolume','featureOpen','featureClose']] = NewsDataframeFinal[['labelVolume','labelOpen','labelClose','featureVolume','featureOpen','featureClose']].astype(object)\nNewsDataframeFinal[['labelVolume','labelOpen','labelClose','featureVolume','featureOpen','featureClose']] = NewsDataframeFinal.apply(queryForPandas, axis = 1)\nNewsDataframeFinal = NewsDataframeFinal[NewsDataframeFinal.notnull()]\nprint('Query Engine Task Finished...')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43c061dc95a327cefbdffaa7ffcc1d9fd2edfba9"},"cell_type":"code","source":"NewsDataframeFinal = NewsDataframeFinal[NewsDataframeFinal.notnull()]\nNewsDataframeFinal = NewsDataframeFinal.dropna()\nNewsDataframeFinal.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8857f873dc7eacbbcde8754f35f16b21fc0ecfc0"},"cell_type":"code","source":"def flat_list(obj):  \n  listVal = [y for x in obj for y in x]\n  return listVal","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12b6813630b2ac7b49e37f0c83aa2516275c72f1"},"cell_type":"code","source":"Data = pd.DataFrame()\nData['label'] = NewsDataframeFinal[['labelVolume','labelOpen','labelClose']].values.tolist()\nData['sentimentFeature'] = NewsDataframeFinal[['urgency','relevance','sentimentPositive','sentimentNeutral','sentimentNegative']].values.tolist()\nData['newsFeature'] = NewsDataframeFinal[['subjectFeatures','audienceFeatures','headlineVector','featureVolume','featureOpen','featureClose']].values.tolist()\nData['newsFeature'] = Data['newsFeature'].apply(flat_list)\ndel NewsDataframeFinal\nData['features'] = Data[['sentimentFeature','newsFeature']].values.tolist()\nData = Data.drop(columns=['sentimentFeature','newsFeature'])\nData['label'] = Data['label'].apply(flat_list)\nData['features'] = Data['features'].apply(flat_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c4598a36f609cdc68e2b49ba7f27528ae09b47f"},"cell_type":"code","source":"Data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65ce7a56f5f9db73bdec063b746acf203241abc1"},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, LSTM, Conv1D, MaxPooling1D, Embedding\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing import sequence\nfrom sklearn.preprocessing import normalize\n\n\nfeatures = Data['features'].values\nlabels = Data['label'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35eabbf4bba1f0d57a084225f84eabb6949df44c"},"cell_type":"code","source":"#hyperparameters\npool_size = 15\nlstm_output_size = 15\nbatch_size = 7000\nepochs = 5\nmax_features = 10000\nmaxlen = 200\nembedding_size = 160\n\nprint('Loading data...')\nx_train, x_test, y_train, y_test = train_test_split(features,labels, test_size= 0.2, random_state=21)\n\nprint('x_train shape:', len(x_train))\nprint('x_test shape:', len(x_test))\nx_train = sequence.pad_sequences(x_train, maxlen=maxlen, padding='post')\nx_test = sequence.pad_sequences(x_test, maxlen=maxlen, padding='post')\ny_train = sequence.pad_sequences(x_train, maxlen=15, padding='post')\ny_test = sequence.pad_sequences(x_test, maxlen=15, padding='post')\nx_train = normalize(x_train)\ny_train = normalize(y_train)\nx_test = normalize(x_test)\ny_test = normalize(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c050d439338b7c0ad5f25da7165b7fe964861f2"},"cell_type":"code","source":"print('Building model...')\nmodel = Sequential()\nmodel.add(Embedding(max_features, embedding_size, input_length=maxlen))\nmodel.add(Dropout(0.5))\nmodel.add(Conv1D (kernel_size = (5), filters = 40, activation='relu'))\nmodel.add(MaxPooling1D(pool_size=pool_size))\nmodel.add(LSTM(lstm_output_size))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(15)) #prediction for next five days so the label should be made such that it has to be 15 dimensional(volume open close 5 days)\nmodel.add(Activation('sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n\nprint('Train...')\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          validation_data=(x_test, y_test))\nscore, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\nmodel.save('my_model.hdf5')\nprint('Test score:', score)\nprint('Test accuracy:', acc)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}